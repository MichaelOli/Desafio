# Fontes de Dados: Reais vs Simulados 

## VisÃ£o Geral

O sistema possui **3 fontes de dados** diferentes que sÃ£o usadas em uma **hierarquia de prioridade**:

```
1. DADOS REAIS DO ERP.json (Prioridade Alta)
2. DADOS REAIS DO DATA LAKE (Prioridade MÃ©dia)  
3. DADOS SIMULADOS (Fallback)
```

---

## **1. DADOS REAIS DO ERP.json**

### **LocalizaÃ§Ã£o:**
```
dados/ERP.json
```

### **ConteÃºdo Real:**
```json
{
  "guestCheckId": "12345678-1234-5678-9012-123456789012",
  "chkNum": 1001,
  "opnBusDt": "2024-01-15",
  "chkTtl": 50.05,
  "gstCnt": 2,
  "detailLines": [
    {
      "menuItem": {
        "itemName": "HambÃºrguer Artesanal",
        "categoryName": "Lanches",
        "unitPrice": 38.90
      }
    },
    {
      "menuItem": {
        "itemName": "Pizza Margherita", 
        "categoryName": "Pizzas",
        "unitPrice": 22.75
      }
    }
  ]
}
```

### **Dados ExtraÃ­dos:**
- **Itens reais:** HambÃºrguer Artesanal, Pizza Margherita
- **Data:** 2024-01-15 (janeiro de 2024)
- **Mesa:** Mesa 12
- **Total:** R$ 50.05
- **Registros:** 4 (2 itens + 1 desconto + 1 imposto)

### **Como Ã© Processado:**
```python
# src/extrair.py - linha ~100
def extrair_dados_erp_restaurante(self):
    dados_erp = self.extrair_json("dados/ERP.json")
    # Processa cada item do menu, desconto e imposto
    # Retorna DataFrame com dados estruturados
```

---

## **2. DADOS REAIS DO DATA LAKE**

### **LocalizaÃ§Ã£o:**
```
dados/data_lake/dados_brutos/
â”œâ”€â”€ bilgetFiscalInvoice/ano=2025/mes=07/dia=31/loja=loja001/
â”œâ”€â”€ getGuestChecks/ano=2025/mes=07/dia=31/loja=loja001/
â”œâ”€â”€ getChargeBack/ano=2025/mes=07/dia=31/loja=loja001/
â”œâ”€â”€ getTransactions/ano=2025/mes=07/dia=31/loja=loja001/
â””â”€â”€ getCashManagementDetails/ano=2025/mes=07/dia=31/loja=loja001/
```

### **ConteÃºdo Real (Exemplo):**
```json
{
  "metadados": {
    "endpoint": "getCashManagementDetails",
    "data_negocio": "2025-07-31",
    "id_loja": "loja001"
  },
  "dados": {
    "cashManagementId": "CM-2024-001",
    "storeId": "loja001", 
    "openingBalance": 500.0,
    "closingBalance": 750.0,
    "totalSales": 1250.0
  }
}
```

### **Dados ExtraÃ­dos:**
- **5 endpoints:** bilgetFiscalInvoice, getGuestChecks, getChargeBack, getTransactions, getCashManagementDetails
- **Data:** 2025-07-31 (julho de 2025)
- **Loja:** loja001
- **Registros:** 15 arquivos (3 de cada endpoint)

### **Como Ã© Processado:**
```python
# src/extrair.py - linha ~360
def extrair_dados_data_lake(self):
    # Busca todos os arquivos JSON nos 5 endpoints
    # Extrai metadados + dados de cada arquivo
    # Consolida em DataFrame Ãºnico
```

---

## **3. DADOS SIMULADOS**

### **LocalizaÃ§Ã£o:**
```
Gerados em memÃ³ria pelo cÃ³digo Python
```

### **ConteÃºdo Simulado:**
```python
# src/extrair.py - linha ~220
itens_menu = [
    {'nome': 'HambÃºrguer Artesanal', 'categoria': 'Lanches', 'preco': 22.75},
    {'nome': 'Pizza Margherita', 'categoria': 'Pizzas', 'preco': 28.50},
    {'nome': 'Lasanha Bolonhesa', 'categoria': 'Massas', 'preco': 24.90},
    {'nome': 'SalmÃ£o Grelhado', 'categoria': 'Peixes', 'preco': 35.00},
    # ... mais itens realistas
]

funcionarios = [
    {'id': 1001, 'nome': 'Maria Silva'},
    {'id': 1002, 'nome': 'JoÃ£o Santos'},
    # ... mais funcionÃ¡rios
]
```

### **Dados Gerados:**
- **PerÃ­odo:** Ãšltimos 90 dias (mÃºltiplas datas)
- **Comandas:** 200 comandas simuladas
- **Itens:** 10 itens diferentes do menu
- **FuncionÃ¡rios:** 5 funcionÃ¡rios diferentes
- **Mesas:** 1-20 (aleatÃ³rio)
- **Registros:** ~800-1000 (dependendo dos itens por comanda)

### **Como Ã© Gerado:**
```python
# src/extrair.py - linha ~220
def gerar_dados_exemplo_restaurante(self, numero_comandas=200):
    # Gera comandas aleatÃ³rias com:
    # - Datas dos Ãºltimos 90 dias
    # - 1-5 itens por comanda
    # - FuncionÃ¡rios e mesas aleatÃ³rios
    # - 20% das comandas tÃªm desconto
```

---

## **LÃ³gica de DecisÃ£o: Qual Fonte Usar?**

### **Algoritmo de Prioridade:**

```python
# src/extrair.py - linha ~430
def extrair_dados_combinados_restaurante(self):
    
    # 1. TENTAR ERP.json
    try:
        dados_erp = self.extrair_dados_erp_restaurante()
        if not dados_erp.empty:
            return dados_erp  
    except:
        pass
    
    # 2. TENTAR DATA LAKE  
    try:
        dados_data_lake = self.extrair_dados_data_lake()
        if not dados_data_lake.empty:
            return processar_data_lake(dados_data_lake)  
    except:
        pass
    
    # 3. FALLBACK: DADOS SIMULADOS
    return self.gerar_dados_exemplo_restaurante(200)  
```

### **CenÃ¡rios PrÃ¡ticos:**

#### **CenÃ¡rio 1: Projeto Completo (Atual)**
```
ERP.json existe â†’ USA DADOS REAIS DO ERP
Resultado: HambÃºrguer Artesanal, Pizza Margherita, 2024-01
```

#### **CenÃ¡rio 2: SÃ³ Data Lake**
```
ERP.json nÃ£o existe
Data Lake existe â†’ USA DADOS REAIS DO DATA LAKE  
Resultado: Dados dos 5 endpoints, 2025-07
```

#### **CenÃ¡rio 3: Projeto Vazio**
```
ERP.json nÃ£o existe
Data Lake nÃ£o existe â†’ USA DADOS SIMULADOS
Resultado: 200 comandas, mÃºltiplos meses, 10 itens variados
```

---

## **Controle no Dashboard**

### **Checkbox "Usar dados reais do ERP/Data Lake":**

#### **Marcado (PadrÃ£o):**
```python
usar_dados_reais = True
dados_df = carregar_dados_restaurante(usar_dados_reais=True)
# â†’ Executa algoritmo de prioridade acima
```

#### **Desmarcado:**
```python  
usar_dados_reais = False
dados_df = carregar_dados_restaurante(usar_dados_reais=False)
# â†’ ForÃ§a uso de dados simulados
```

---

## ğŸ“Š **ComparaÃ§Ã£o das Fontes**

| Aspecto | ERP.json | Data Lake | Simulados |
|---------|----------|-----------|-----------|
| **Realismo** | 100% Real | 100% Real | Realista |
| **Volume** | Poucos dados | MÃ©dio | Muitos dados |
| **PerÃ­odos** | 1 mÃªs | 1 mÃªs | 3 meses |
| **TendÃªncias** | ImpossÃ­vel | ImpossÃ­vel | PossÃ­vel |
| **CorrelaÃ§Ãµes** | Limitadas | Limitadas | Ricas |
| **Insights** | BÃ¡sicos | BÃ¡sicos | AvanÃ§ados |

---

## **Como Verificar Qual Fonte EstÃ¡ Sendo Usada**

### **1. Logs do Sistema:**
```bash
python demo_streamlit.py

# SaÃ­da mostra a fonte:
INFO:src.extrair:Dados ERP extraÃ­dos: 4 registros  â† ERP.json
INFO:src.extrair:Dados data lake extraÃ­dos: 15 registros  â† Data Lake  
INFO:src.extrair:Gerando dados simulados para demonstraÃ§Ã£o  â† Simulados
```

### **2. Dashboard:**
```
Fonte dos dados: Dados Reais (ERP + Data Lake)  â† Reais
Fonte dos dados: Dados Simulados  â† Simulados
```

### **3. Dados EspecÃ­ficos:**
```
ERP.json: HambÃºrguer Artesanal, Pizza Margherita, 2024-01
Simulados: Lasanha Bolonhesa, SalmÃ£o Grelhado, mÃºltiplas datas
```

---

## **RecomendaÃ§Ãµes de Uso**

### **Para Testar Funcionalidades:**
```
Desmarque "Usar dados reais"
â†’ Veja anÃ¡lise completa com tendÃªncias e correlaÃ§Ãµes
```

### **Para Dados Reais do NegÃ³cio:**
```
Marque "Usar dados reais"  
â†’ Veja dados reais do ERP, mesmo que limitados
```

### **Para DemonstraÃ§Ãµes:**
```
Alterne entre os dois para mostrar:
- Dados reais: Autenticidade
- Dados simulados: Funcionalidades completas
```

---

## **Resumo**

**O sistema Ã© inteligente e flexÃ­vel:**

1. **Prioriza dados reais** quando disponÃ­veis
2. **Fallback automÃ¡tico** para dados simulados
3. **Controle manual** via checkbox
4. **TransparÃªncia total** sobre qual fonte estÃ¡ sendo usada

**Resultado:** VocÃª sempre tem dados para analisar, sejam reais ou simulados, com total controle e visibilidade sobre a fonte!

---

## **Insights AutomÃ¡ticos:**

### **NÃƒO Ã‰ INTELIGÃŠNCIA ARTIFICIAL**

Os "insights automÃ¡ticos" sÃ£o gerados por **regras programÃ¡ticas simples**, nÃ£o por IA:

```python
# Exemplo real do cÃ³digo:
def gerar_insights_automaticos(self, dados_df):
    insights = []
    
    # 1. Ranking simples
    item_top = dados_df.groupby('nome_item')['valor_item'].sum().idxmax()
    insights.append(f"O item mais vendido em valor Ã©: {item_top}")
    
    # 2. ClassificaÃ§Ã£o por limiar
    ticket_medio = dados_df.groupby('guest_check_id')['valor_item'].sum().mean()
    if ticket_medio > 100:
        insights.append("O ticket mÃ©dio Ã© alto, indicando bom valor por comanda")
    else:
        insights.append("O ticket mÃ©dio Ã© moderado, foco em aumentar itens")
    
    # 3. IdentificaÃ§Ã£o de padrÃµes
    mes_pico = dados_df.groupby(dados_df['data_abertura'].dt.month)['valor_item'].sum().idxmax()
    insights.append(f"O mÃªs com maior faturamento Ã© {meses[mes_pico-1]}")
    
    return insights
```

### **Tipos de "Insights" Gerados:**

| Tipo | Exemplo | MÃ©todo |
|------|---------|--------|
| **Rankings** | "Item mais vendido: HambÃºrguer" | `groupby().sum().idxmax()` |
| **ClassificaÃ§Ãµes** | "Ticket mÃ©dio Ã© alto (R$ 45.50)" | `if valor > limiar` |
| **PadrÃµes Temporais** | "MÃªs de pico: Janeiro" | `groupby(mes).sum().idxmax()` |
| **ComparaÃ§Ãµes** | "Mesa 12 tem maior faturamento" | `groupby().sum().sort_values()` |

### **O que Ã‰ (Regras ProgramÃ¡ticas):**
- AgregaÃ§Ãµes SQL simples (GROUP BY, MAX, AVG)
- Condicionais if/else bÃ¡sicas
- Templates de texto prÃ©-definidos
- EstatÃ­sticas descritivas

### **O que NÃƒO Ã‰ (IA Real):**
- Aprendizado de mÃ¡quina
- Redes neurais
- Processamento de linguagem natural
- AnÃ¡lise preditiva complexa
- Reconhecimento de padrÃµes avanÃ§ados

### **Exemplo de SaÃ­da Real:**
```
Insights AutomÃ¡ticos:
1. O mÃªs com maior faturamento Ã© Jan
2. O item mais vendido em valor Ã©: HambÃºrguer Artesanal  
3. A categoria com melhor performance Ã©: Lanches
4. O funcionÃ¡rio com melhor performance Ã©: Maria Silva
5. O ticket mÃ©dio Ã© moderado (R$ 45.50), foco em aumentar itens por comanda
6. A mesa com maior faturamento Ã© a Mesa 12
7. O preÃ§o mÃ©dio dos itens Ã© acessÃ­vel (R$ 22.75), foco em volume
8. O dia da semana com maior movimento Ã© Segunda-feira
```

**ConclusÃ£o:** SÃ£o "insights automÃ¡ticos inteligentes" mas baseados em regras simples, nÃ£o em IA!

---

## **AnÃ¡lise de CorrelaÃ§Ã£o: Como Funciona**

### **Matriz de CorrelaÃ§Ã£o Melhorada**

A anÃ¡lise de correlaÃ§Ã£o tambÃ©m **nÃ£o usa IA**, mas sim **estatÃ­stica tradicional**:

```python
# CÃ¡lculo de correlaÃ§Ã£o (Pearson)
correlacao = dados_df[colunas_numericas].corr()

# InterpretaÃ§Ã£o automÃ¡tica
for i, j in correlacao:
    valor_corr = correlacao.iloc[i, j]
    if valor_corr > 0.7:
        tipo = "CorrelaÃ§Ã£o muito forte positiva"
        explicacao = f"Quando {var1} aumenta, {var2} tambÃ©m aumenta significativamente"
```

### **Melhorias Implementadas:**

1. preco_unitario â†” valor_item
   CorrelaÃ§Ã£o muito forte positiva (0.85)
   Quando preco_unitario aumenta, valor_item tambÃ©m aumenta significativamente

Insights PrÃ¡ticos:
Itens com preÃ§os mais altos geram maior faturamento - considere estratÃ©gias de upselling
```

### **Processo de InterpretaÃ§Ã£o:**

1. **CÃ¡lculo:** CorrelaÃ§Ã£o de Pearson entre variÃ¡veis numÃ©ricas
2. **Filtragem:** Apenas correlaÃ§Ãµes > 0.3 (significativas)
3. **ClassificaÃ§Ã£o:** Por forÃ§a da correlaÃ§Ã£o
4. **InterpretaÃ§Ã£o:** Templates baseados em regras
5. **Insights:** SugestÃµes prÃ¡ticas para restaurante

---

## **AnÃ¡lise de TendÃªncias: LimitaÃ§Ãµes dos Dados Reais**

### **Problema Identificado:**

```
Dados Atuais:
- ERP.json: 2024-01-15 (janeiro de 2024)
- Data Lake: 2025-07-31 (julho de 2025)
- Resultado: Apenas 1 perÃ­odo apÃ³s limpeza

AnÃ¡lise de TendÃªncias:
Melhor PerÃ­odo: 2024-01 (R$ 45.50)
Pior PerÃ­odo: 2024-01 (R$ 45.50)  â† Iguais!
```

### **SoluÃ§Ã£o Implementada:**

#### **Interface Melhorada:**
```
Dados Insuficientes para AnÃ¡lise de TendÃªncias

Atualmente temos dados de apenas 1 perÃ­odo (2024-01).

Para uma anÃ¡lise de tendÃªncias significativa, precisamos de dados de mÃºltiplos meses.

SugestÃµes:
- Aguarde mais dados histÃ³ricos serem coletados
- Use dados simulados (desmarque "Usar dados reais") para ver como funcionaria
- Considere analisar tendÃªncias diÃ¡rias ao invÃ©s de mensais
```

#### **ComparaÃ§Ã£o Visual:**
```
Melhor PerÃ­odo: 2024-01 (R$ 45.50)
PerÃ­odo Ãšnico: 2024-01 (R$ 45.50)
Apenas um perÃ­odo disponÃ­vel  â† ExplicaÃ§Ã£o clara!
```

### **RecomendaÃ§Ã£o:**
Para ver anÃ¡lise de tendÃªncias completa, use **dados simulados** que cobrem 90 dias com mÃºltiplas datas.

---

## **Processamento e TransformaÃ§Ã£o de Dados**

### **Pipeline ETL Completo:**

```
1. EXTRACT (Extrair)
   â”œâ”€â”€ ERP.json â†’ 4 registros (2 itens + 1 desconto + 1 imposto)
   â”œâ”€â”€ Data Lake â†’ 15 registros (5 endpoints Ã— 3 arquivos)
   â””â”€â”€ Simulados â†’ 800-1000 registros (200 comandas)

2. TRANSFORM (Transformar)
   â”œâ”€â”€ Limpeza: Remove registros invÃ¡lidos
   â”œâ”€â”€ PadronizaÃ§Ã£o: Nomes, datas, valores
   â”œâ”€â”€ Enriquecimento: Colunas derivadas (ano, mÃªs, dia_semana)
   â””â”€â”€ ValidaÃ§Ã£o: Constraints de negÃ³cio

3. LOAD (Carregar)
   â”œâ”€â”€ DataFrame estruturado
   â”œâ”€â”€ MÃ©tricas calculadas
   â””â”€â”€ Pronto para anÃ¡lise
```

### **Exemplo de TransformaÃ§Ã£o:**

#### **Dados Brutos (ERP.json):**
```json
{
  "detailLines": [{
    "menuItem": {
      "itemName": "HambÃºrguer Artesanal",
      "unitPrice": 22.75,
      "dspQty": 1
    }
  }]
}
```

#### **Dados Transformados:**
```python
{
  'nome_item': 'HambÃºrguer Artesanal',
  'preco_unitario': 22.75,
  'quantidade': 1,
  'valor_item': 22.75,
  'categoria': 'Lanches',
  'ano': 2024,
  'mes': 1,
  'dia_semana': 'Monday',
  'ticket_comanda': 45.50
}
```

---

## **Controles AvanÃ§ados do Dashboard**

### **Filtros DinÃ¢micos:**

```python
# Filtros especÃ­ficos para restaurante
filtros_disponiveis = {
    'item_menu': dados_df['nome_item'].unique(),
    'categoria': dados_df['categoria'].unique(), 
    'funcionario': dados_df['nome_funcionario'].unique(),
    'mesa': dados_df['numero_mesa'].unique()
}

# AplicaÃ§Ã£o de filtros
dados_filtrados = dados_df.copy()
if item_selecionado != 'Todos':
    dados_filtrados = dados_filtrados[dados_filtrados['nome_item'] == item_selecionado]
```

### **MÃ©tricas Calculadas em Tempo Real:**

```python
# MÃ©tricas principais
metricas = {
    'faturamento_total': dados_filtrados['valor_item'].sum(),
    'total_comandas': dados_filtrados['guest_check_id'].nunique(),
    'ticket_medio': dados_filtrados.groupby('guest_check_id')['valor_item'].sum().mean(),
    'itens_vendidos': len(dados_filtrados)
}
```
## **Performance e OtimizaÃ§Ãµes**

### **Cache Inteligente:**

```python
@st.cache_data
def carregar_dados_restaurante(usar_dados_reais=True):
    # Dados sÃ£o carregados apenas uma vez
    # Recarregados apenas quando parÃ¢metros mudam
```

### **Filtragem Eficiente:**

```python
# Filtros aplicados em sequÃªncia otimizada
dados_filtrados = dados_df.copy()
for filtro, valor in filtros_ativos.items():
    if valor != 'Todos':
        dados_filtrados = dados_filtrados[dados_filtrados[filtro] == valor]
```

### **Processamento Sob Demanda:**

```python
# MÃ©tricas calculadas apenas quando necessÃ¡rio
if tab_selecionada == 'tendencias':
    tendencias = analisador.analisar_tendencias(dados_filtrados)
elif tab_selecionada == 'correlacoes':
    correlacoes = analisador.criar_heatmap_correlacao(dados_filtrados)
```

---

## **Resumo TÃ©cnico Completo**

### **Arquitetura:**
```
Interface (Streamlit) 
    â†“
Controle de Dados (app_streamlit.py)
    â†“
Pipeline ETL (src/)
    â”œâ”€â”€ Extrair (extrair.py) â†’ ERP.json + Data Lake + Simulados
    â”œâ”€â”€ Transformar (transformar.py) â†’ Limpeza + Enriquecimento  
    â””â”€â”€ Analisar (analisar.py) â†’ Insights + CorrelaÃ§Ãµes + TendÃªncias
    â†“
VisualizaÃ§Ã£o (Plotly + Streamlit)
```

### **Funcionalidades:**
- **3 fontes de dados** com priorizaÃ§Ã£o automÃ¡tica
- **Insights automÃ¡ticos** baseados em regras (nÃ£o IA)
- **CorrelaÃ§Ãµes intuitivas** com interpretaÃ§Ã£o automÃ¡tica
- **AnÃ¡lise de tendÃªncias** com tratamento de dados insuficientes
- **Dashboard interativo** com filtros dinÃ¢micos
- **Cache inteligente** para performance


